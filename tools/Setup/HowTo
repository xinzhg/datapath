This document describes how to setup the BlueStreak system.

1. Create the system metadata
The metadata used throughout the entire system is kept in a SQLITE database.
There are multiple types of metadata:
	a) Storage metadata
Storage metadata contains information on the disks/partitions/files where the data in a database used by BlueStreak is stored. BlueStreak is a multi-disk database and uses striping to evenly distribute the data across the available disks. The disks are seen as devices and preferably they should not be mounted into the file system (for performance reasons). The metadata corresponding to the disks is stored into two tables in the SQLITE database: DiskArrays and Stripes. DiskArrays contains generic data on the storage system such as PAGESIZE, the first free page available for use, and striping parameters. Stripes contains data on the actual disks such as the corresponding file name.
Data on the layout of the existing relations is maintained in the tables: Relations, Chunks, and Columns. Relations contains data on the available relations in the system, while Columns contains data on the attributes of the relations. A chunk can be seen as a continuous sequence of pages that contain data from a particular column of a relation (there is a maximum number of tuples allowed in a chunk).

	b) Catalog metadata
Catalog metadata contains information on properties of the system (parameters) and on the databases existing in the system (relations, attributes). The parameters are used throughout the system and they are required to setup a working BlueStreak instance. Such parameters are: memory allocated to the global hash table for join processing, number of worker threads, etc. Table CatalogConstants contains the system parameters. Tables CatalogRelations and CatalogAttributes are similar to the corresponding tables Relations and Columns in containing data on the relations existing in the system, but they contain generic information rather than disk layout information. The data in the catalog is used to check query validity and for query optimization.

The script InitializeSystem.sh in Tools/Setup initializes a BlueStreak instance by creating a SQLITE database instance for storing the metadata.

2. Initialize the storage system
The script AddDiskArray.sh in Tools/Setup creates and initializes a disk array by inserting the user provided data into the tables DiskArrays and Stripes in the metadata SQLITE database.

3. Bulk-load data
The next step after a BlueStreak instance is set-up is to load data. An optimized bulk-loader is generated to insert data for every relation. The data can be either pre-generated and stored in a series of files or it can be generated at run-time and simultaneously loaded into BlueStreak,
Here we describe the steps to load data into BlueStreak.

	a) Relation definition
An M4 file containing the schema of the relation to be loaded and the data sources where the data is located has to be defined for each individual relation. The definition of this file is straightforward and there are examples available in Tools/BulkLoader. A symbolic link to the relation definition file has to be created with the name FileLoaderDefs.m4 located in Tools/BulkLoader.

	b) Compilation and execution
The BulkLoader binary has to be generated by compiling the files in Tools/BulkLoader. Simply run make in this directory. To run the bulk loader, run ./bulkLoader in Tools/BulkLoader if the compilation executed correctly. If the data is generated simultaneously with loading, the data generation processes have to be started accordingly. The communication between the data generators and the bulk loader is done through files, preferably pipes.

Commands:

1. Initialize the system
w_command-hadoop
/home/frusu/svn/BlueStreak/DataPath/trunk/tools/Setup/InitializeSystem-silent.sh
/localHD/BlueStreak/datapath.sqlite

2. Add the storage system (disk array)
w_command-hadoop
/home/frusu/svn/BlueStreak/DataPath/trunk/tools/Setup/AddDiskArray-silent.sh
/localHD/BlueStreak/datapath.sqlite "Default" 512 1 "/dev/sda" 2

3. Run the bulk loader (this needs to be run as root or with access to /dev/sda2)
wb_command-hadoop
/home/frusu/BlueStreak/src/BulkLoader.out /localHD/BlueStreak/datapath.sqlite

When compiling the bulk loader, the file FileLoaderDefs.m4 needs to contain (point)
to the file with the description of the relation to be loaded. This is also an m4
file. Usually a hard link needs to be made between the relation description file
and FileLoaderDefs.m4:
ln Rankings.m4 FileLoaderDefs.m4
